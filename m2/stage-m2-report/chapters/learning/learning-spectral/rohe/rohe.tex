\documentclass[../../main.tex]{subfiles} % Allows individual compilation
\graphicspath{{\subfix{./images/}}}

\begin{document}
	
	\section{Consistency of spectral clustering}
	
	\subsection{Notations, conventions, definitions.}
	\marginnote{Motivation} When studying the relationship between SBMs and 
	spectral clustering algorithms, it is natural to ask when is the 
	spectral clustering algorithm capable of recovering the community 
	partitions of graphs generated under some SBM. The seminal work of 
	\cite{rohe_spectral_2011} was among the first to study this question. 
	Figure \ref{fig:tikz-diagram-rohe} is a schematic diagram linking the 
	results presented in it. Lemma 3.1. will be of particular interest for 
	connections with probabilistic approaches.
	
	\begin{figure}
		\ifthenelse{\boolean{addtikz}}{
			\subfile{./images/tikz/diagram_rohe/diagram_rohe.tex}
		}{
			\includegraphics{example-image-a}
		}
		\caption{Diagram of results in \cite{rohe_spectral_2011}.}
		\label{fig:tikz-diagram-rohe}
	\end{figure}
	 
	\marginnote{General latent space models} It is important to notice 
	that all the results concerning the first objective in Figure 
	\ref{fig:tikz-diagram-rohe} are valid for latent space models, which is a 
	class of models more general than the SBM.
	
	\begin{definition}[Latent space model]
		For i.i.d. random vectors \(z_1, \dots, z_n \in \mathbb R^{k}\) and 
		random 
		adjacency matrix \(A \in \{0,1\}^{n \times n}\), let \(\mathbb P 
		(A_{ij} 
		\vert z_i, z_j)\) be the probability mass function of \(A_{ij}\) 
		conditioned on \(z_i, z_j\). If a probability distribution on \(A\) has 
		the 
		conditional dependence relationships
		\begin{equation*}
			\mathbb P (A \vert z_1, \dots, z_n) = \prod_{i < j} \mathbb P 
			(A_{ij} 
			\vert z_i, z_j),
		\end{equation*}
		and \(\mathbb P (A_{ii} = 0) = 1\) for all \(i\), then it is called an 
		\textit{undirected latent space model}.
	\end{definition}
	
	\marginnote{Choice of Laplacian} They use the matrix \(L = D^{-1/2} A 
	D^{-1/2}\) as Laplacian. This is justified, since this matrix has the same 
	eigenvectors as the more common normalized Laplacian \(\tilde L = I - L\), 
	and the eigenvectors are the only thing that matters in the spectral 
	clustering algorithm. However, due care should be taken when translating 
	their results to those obtained when using the unnormalized Laplacian. 
	The population adjacency matrix is defined as \(\mathscr A \coloneqq 
	\mathbb E [A \vert Z^{\star}]\), and the population degree matrix is the 
	diagonal matrix with diagonal entries \(\mathscr D_{ii} = \sum_k \mathscr 
	A_{ik}\). This allows the definition of the population Laplacian \(\mathscr 
	L = \mathscr D^{-1/2} \mathscr A \mathscr D^{-1/2}\). Their work consists 
	of two parts.
	
	\subsection{First part: convergence of eigenvectors}
	The first part consists in showing that the eigenvectors of the empirical 
	Laplacian converge in some sense to the eigenvectors of the population 
	Laplacian. This would be immediate if these matrices converged in Frobenius 
	norm, i.e., if \(\Vert L - \mathscr L \Vert_F \to 0\). However, they do not 
	converge in such a norm, and so a ``detour'' needs to be made in order to 
	achieve this result. They show instead that the \textit{squared} version of 
	these matrices converge in Frobenius norm, and then show directly that this 
	implies that \textit{up to a rotation} the eigenvectors of \(L\) converge 
	to those of \(\mathscr L\). 
	
	\subsection{Second part: retrieval for spectral clustering}
	The results of this part focus on the special case of an SBM, and shows the 
	asymptotic consistency when using the spectral clustering algorithm to 
	estimate the community assignment clatent variables \(Z^{\star}\). It 
	starts with the following lemma, which shows that applying the algorithm to 
	the expected Laplacian given the assignments recovers precisely the 
	partitions of the SBM. Notice that this fact is non-asymptotic.
	
	\begin{lemma}
		Consider the Stochastic Blockmodel with \(k\) blocks,
		\begin{equation*}
			\mathscr A = Z \Gamma Z^t \in \mathbb R^{n \times n} 
			\, \text{ for } \, \Gamma \in \mathbb R^{k \times k} \, \text{ and 
			} \, Z \in 
			\{0, 1\}^{n \times k},
		\end{equation*}
		and let \(\mathscr L\) be the expected Laplacian given the true 
		assignments \(Z^{\star}\). Then, there exists a matrix \(\mu \in 
		\mathbb R^{k \times k}\) such that the eigenvectors of \(\mathscr L\) 
		corresponding to the nonzero eigenvalues are the columns of the \(Z 
		\mu\). Furthermore,
		\begin{equation} \label{eq:equivalence_rohe}
			z_i \mu = z_j \mu \iff z_i = z_j,
		\end{equation}
		where \(z_i\) is the \(i\)-th row of \(Z\).
	\end{lemma}

	\begin{remark}
		The equivalence in Equation \ref{eq:equivalence_rohe} means that rows 
		\(i\) and \(j\) of \(Z \mu\) are equal if, and only if, the 
		corresponding rows of \(Z\) are equal, that is, if nodes \(i\) and 
		\(j\) belong to the same community. Since there are \(k\) communities, 
		this implies that there can be at most \(k\) unique rows in 
		the matrix \(Z \mu\) of eigenvectors of \(\mathscr L\). Spectral 
		clustering applies \(k\)-means to these vectors, and thus these become 
		precisely the centroids of \(k\)-means (since one is applying 
		\(k\)-means to at most \(k\) different vectors). The rows of \(Z \mu\) 
		will then obviously be attributed to the centroid they are equal to, 
		and by the equivalence in Equation \ref{eq:equivalence_rohe}, this 
		implies that spectral clustering perfectly identifies the clusters in 
		the expected Laplacian \(\mathscr L\).
	\end{remark}

	\begin{proof}
		Here is a sketch of the proof, which is quite algebraic and not much 
		motivated.
		\begin{enumerate}
			\item Factor \(\mathscr L\) as \(\mathscr L = Z \Gamma_L Z^t\) for 
			some matrix \(\Gamma_L \in \mathbb R^{k \times k}\).
			\item Consider now the (different) matrix \((Z^t Z)^{1/2} \Gamma_L 
			(Z^t Z)^{1/2}\): 
			this is the decomposition given for \(\mathscr L\) under 
			the change \(Z \to (Z^t Z)^{1/2}\), which can be thought of as a 
			``square matrix version'' of \(Z\).
			\item Show that \((Z^t Z)^{1/2} \Gamma_L (Z^t Z)^{1/2}\) is 
			symmetric and positive-definite, implying the spectral 
			decomposition 
			\((Z^t Z)^{1/2} \Gamma_L (Z^t Z)^{1/2} = V \Lambda V^t\).
			\item Multiply the spectral decomposition on both sides by \((Z^t 
			Z)^{-1/2} Z^t\), revealing that
			\begin{equation} \label{eq:proof-rohe}
				Z \Gamma_L Z^t = \mathscr L = (Z \mu) \Lambda (Z \mu)^t
			\end{equation}
			for \(\mu \coloneqq (Z^t Z)^{-1/2} V\).
			\item Together with the fact that \((Z \mu)^t (Z \mu) = I_k\), 
			where \(I_k\) is the \(k \times k\) identity, Equation 
			\ref{eq:proof-rohe} is precisely the eigenvector equation for 
			\(\mathscr L\). This shows that the columns of \(Z \mu\) are the 
			eigenvectors of \(\mathscr L\) associated to the non-zero 
			eigenvalues.
			\item Finally, the equivalence is a direct consequence of the fact 
			that \(\mu\) is invertible:
			\begin{equation*}
				\det(\mu) = \det((Z^t Z)^{-1/2}) \det(V) > 0.
			\end{equation*} 
		\end{enumerate}

	\end{proof}
	
\end{document}