---
title: "Modélisation de saisonnalités complexes avec GAMs"
author: "Leonardo Martins Bianco - Guillaume Lambert"
date: "05/03/2021"
bibliography: references_projet_sc.bib
nocite: '@*'
output:
  pdf_document: default
  html_document: default
---

# Introduction

Nous avons choisi d'étudier des données météorologiques de la **National Oceanic and Atmospheric Administration (NOAA)**, une agence états-unienne responsable de la préservation, la surveillance, l'évaluation et l'accès publique aux données et informations météorologiques. Les données que nous avons utilisées font parties des **Local Climatological Data (LCD)**, regroupant des données par heure, jour et mois sur un ensemble d'environ 1600 stations météorologiques aux Etats-Unis.

Même si les données semblent simples, la haute fréquence des observations implique un caractère de saisonnalité complexe. C'est-à-dire que les observations horaires donnent une saisonnalité journalière ("locale"), mais aussi une saisonnalité annuelle ("globale").

Les méthodes classiques, en particulier celles implémentées pour l'objet $\texttt{ts}$, ne sont pas capables de traiter ces complexités saisonnales. On présente ici deux alternatives. Plus récemment (2012) [@rob_hynd_changehist] une nouvelle classe $\texttt{msts}$ ("Multiple seasonality time series") a été implémentée pour traiter ces difficultés. On va l'utiliser dans ce projet pour le comparer à un modèle GAM. On fera une étude de la complexité du modèle GAM et on expliquera comment choisir la base selon une étude graphique et une étude des performances. On verra que les résultats sont considérablement meilleurs que ceux obtenus par $\texttt{msts}$ et en moins de temps. On terminera notre travail par l'étude des résidus de notre modèle GAM pour déterminer son efficacité.

# Présentation et mise en forme des données

Nous avons choisi la station météorologique **JFK INTERNATIONAL AIRPORT, NY US**. Elle est située à 3.4 mètres en hauteur et ses coordonnées latitude/longitude sont 40.63915°, -73.76401°. 

<!---<p align="center">
  <img width=40% height=40% src="emplacement.PNG">
</p>
<p align="center">
  <em>Emplacement de la station météorologique</em>
</p>--->

![Emplacement de la station météorologique](./emplacement.PNG){width=40%}

La période de mesure est de 01-07-1948 à 22-02-2021. On télécharge les données sur la période 01-01-2010 à 31-12-2019, ce qui représente un nombre conséquent d'observations permettant une bonne étude des données. On importe les données :

```{r LIBRAIRIES, message=FALSE, include=FALSE}
# Effacer les données dans l'environment avant de commencer
rm(list=objects())

# Librairies
library(tidyverse)
library(lubridate)
library(xts)
library(mgcv)
library(Metrics)
library(forecast)

# Dossier principal
#setwd("C:/Users/lambe/OneDrive/Bureau/projet sc")
```

```{r DONNEES_IMPORT, message=FALSE, warning=FALSE}
data_brute <- read_delim("meteo.csv",delim=",")
```

Ce jeu de données est très dense en informations : il y a 124 variables. La première chose à faire est de comprendre les données et les mettre en forme. 

La première variable **STATION** est le numéro de la station météorologique que l'on étudie : 74486094789. Etant donné que l'on en étudie des données issues d'une seule station, on peut se séparer de cette variable. La deuxième variable **DATE** étant primordiale dans l'étude de séries chronologiques, on la garde. On garde également la variable **SOURCE** qui va nous permettre de nettoyer les données. Finalement, on extrait également les variables par heure et par jour.

```{r DONNEES_EXTRACTION_HEURE_JOUR,include=FALSE}
data_brute <- data_brute[c(2,4,19:38,42:57)]
```

On remarque que lorsque **SOURCE** = 6, la ligne correspondante est consacrée aux valeurs journalières et donc les valeurs horaires sont par défaut. On doit donc prendre les lignes telles que **SOURCE** $\neq 6$.

```{r DONNEES_FILTRAGE_SOURCE_6}
data_brute <- data_brute[which(data_brute$SOURCE != 6),]
```

D'autre part, on remarque que la première date de notre jeu de données est *2010-01-01 00:51:00* et que parmi les lignes où **SOURCE** = 7, il y a une incrémentation d'une heure à partir de *2012-01-01 00:51:00*. C'est donc ces lignes qui nous intéresse car on souhaite étudier la température au fil des heures. Les lignes où **SOURCE** = 4 correspondent à des dates avec heures "rondes" (par exemple *2012-01-01 01:00:00*), elles ne nous intéresse donc pas. On retire donc les lignes où **SOURCE** = 4, puis on retire les lignes où **SOURCE** = 7 avec des dates non incrémentées de la date de départ *2010-01-01 00:51:00*.

```{r DONNEES_FILTRAGE_SOURCE_4}
data_brute <- data_brute[which(data_brute$SOURCE != 4),]
data_brute <- data_brute[which(minute(data_brute$DATE)==51),]
```

Concernant la variable **HourlyDryBulbTemperature**, la documentation nous donne l'indication suivante : "This is the dry-bulb temperature and is commonly used as the standard air temperature reported". Cette colonne correspond donc bien à ce que l'on cherche. On prend donc les colonnes **DATE** et **HourlyDryBulbTemperature**.

```{r DONNEES_FILTRAGE_DATA_TEMPERATURE,include=FALSE}
data <- data_brute[c(1,25)]
```

Vérifions le type des deux variables :

```{r DONNEES_STRUCTURE}
# Vérifions le type des deux variables :
str(data$DATE)
str(data$HourlyDryBulbTemperature)
```

La variable **DATE** est bien sous format d'une date *POSIXct* et la variable **HourlyDryBulbTemperature** est sous le format numérique *num*. Aucune valeur d'un autre type est observée et le nombre total d'observations est le même pour les 2 variables : 87098. 

On convertit ensuite les températures de degrés Fahrenheit en degrés Celsius et on arrondi les valeurs à 4 chiffres décimaux.

```{r DONNEES_CONVERSION_TEMPERATURE, message=FALSE, warning=FALSE, include=FALSE}
# Définition de la fonction de conversion
conversion <- function(temp) {
  t <- (temp - 32) * 5 / 9
  t
}

# Application de la fonction de conversion aux données
data$HourlyDryBulbTemperature <- lapply(data$HourlyDryBulbTemperature,conversion)

# Précision numérique
data$HourlyDryBulbTemperature <- lapply(data$HourlyDryBulbTemperature,round,4)

# Mise des données en format data.frame
data <- data.frame(data$DATE,unlist(data$HourlyDryBulbTemperature))
names(data) <- c("DATE","HourlyDryBulbTemperature")
```

Avant de procéder à l'analyse descriptive des données, on vérifie que notre jeu de données est complet.

```{r DONNEES_MANQUANTES}
data[!complete.cases(data),]
```

Seules 2 valeurs de la températures sont manquantes. On décide de remplacer ces 2 valeurs par la température de l'heure suivante. On assume ce choix car la température varie peu d'une heure à l'autre et cela concerne 2 observations sur 87098.

```{r DONNEES_REMPLACEMENT, message=FALSE, warning=FALSE, include=FALSE}
data$HourlyDryBulbTemperature[72766] <- data$HourlyDryBulbTemperature[72767]
data$HourlyDryBulbTemperature[79909] <- data$HourlyDryBulbTemperature[79910]
```

On renseigne ensuite le fuseau horaire *EST: Eastern Standard Time (North America)* à la variable **DATE** : 

```{r DONNEES_FUSEAU_HORAIRE} 
data$DATE <- with_tz(data$DATE,"EST")
```

Finalement, pour créer nos modèles et faire des prédictions, on sépare les données que l'on a traité en deux : une partie d'entraînement du modèle **trainData** et une partie de prévision **testData**. On ajoute aussi des variables auxiliaires temporelles : **Heure** l'heure de la journée, **NumJour** le numéro du jour dans l'année et **NumSem** le numéro de la semaine dans l'année. 

```{r DONNEES_DESC_AUXILIAIRES, include=FALSE}
# Variable avec l'heure dans la journée de chaque observation
data$Heure <- hour(data$DATE)

# Variable avec le numéro de la semaine dans l'année de chaque observation
data$NumSem <- week(data$DATE)

# Variable avec le numéro du jour dans l'année (va de 1 jusqu'à 365)
data$NumJour <- yday(data$DATE)

# Séparation du jeu de données en parties d'entraînement et de prédiction
trainData <- data[(24*31):(length(data$DATE)-24*365),]
testData <- data[(length(data$DATE)-24*365):length(data$DATE),]

# Variable que numérote chaque observation
trainData$indices <- index(trainData)
testData$indices <- index(testData)
```

# Analyse descriptive des données

Après avoir mis en forme les données, la prochaine étape de notre étude est l'analyse descriptive de nos données. Tout d'abord, calculons les statistiques de base :

```{r DONNEES_DESC_SUMMARY}
summary(data[-c(3, 4, 5)])
```

La variable **DATE** varie de *2010-01-01 00:51:00* à *2019-12-31 23:51:00* avec une incrémentation d'une heure à chaque observations.

La variable **HourlyDryBulbTemperature** prend ses valeurs dans l'intervalle $[-17.222,38.889]$. La moyenne et la médiane sont très proches : 13.009 et 13.333 respectivement. Ainsi, les valeurs extrêmes ne semblent pas déformer la moyenne à première vue. 

Représentons la boîte à moustaches de la température :

```{r DONNEES_DESC_BOX_PLOT, echo=FALSE, fig.height=3, fig.width=3, fig.align='center'}
boxplot(data$HourlyDryBulbTemperature, ylab = "Température", col=rgb(0,1,0,0.5), main="Boîte à moustaches de la température")
```

On retrouve visuellement le fait que la moyenne et la médiane sont proches. On remarque un phénomène intéressant concernant les quartiles : le premier quartile (des valeurs les plus basses) est plus grand que le dernier quartiles (des valeurs les plus hautes). On en déduit que les 25% des températures les plus basses balayent plus de valeurs que les 25% des températures les plus hautes. D'autre part, on remarque que les premier et quatrième quartiles sont plus grands que les deuxième et troisième. Cela veut dire que la moitié des températures intermédiaires sont concentrées autour de la médiane, par rapport à la moitié des températures "extrêmes".

On peut aussi visualiser cette répartition sur l'histogramme suivant, où on représente en bleu les températures inférieures à 0 degrés et en rouge les température supérieures à 25 degrés :

```{r DONNEES_DESC_HISTOGRAMME, echo=FALSE, fig.height=3, fig.width=3, fig.align='center'}
hist_temp <- hist(data$HourlyDryBulbTemperature, breaks = 60, plot=F)
 
# Vecteur couleur
my_color= ifelse(hist_temp$breaks < 0, rgb(0.0,0.0,1,0.5) , ifelse (hist_temp$breaks >=25, rgb(1,0,0,0.5), rgb(0,0,0,0.5) ))
 
# Final plot
plot(hist_temp, col=my_color , border=F , xlab = "Température", ylab = "Fréquence", main = "Histogramme de la température")
```

On remarque que la répartition des températures a une allure gaussienne. 

On va maintenant étudier la tendance et la saisonnalité apparentes de la température par rapport au temps. Représentons la variable **HourlyDryBulbTemperature** par rapport à la variable **DATE** :

```{r DONNEES_DESC_PLOT_GENERAL_, echo=FALSE, fig.height=4}
# Plot avec ggplot2
ggplot(data, aes(x=DATE, y=HourlyDryBulbTemperature)) + ggtitle("Température sur 10 ans") +  geom_line(color="darkblue", size=0.1) + scale_y_continuous(name="Température")
```

On ne distingue pas avec assurance une tendance. On se dit intuitivement qu'elle sera affine avec une pente très faible. On choisit donc de modéliser la tendance par une régression avec un intercept (pour capturer l'ordonnée à l'origine) et une variable **t** numérotant les observations (pour capturer la pente) :

```{r DONNEES_DESC_PLOT_GENERAL, echo=FALSE, fig.height=4, message=FALSE, warning=FALSE}
t <- c(1:length(trainData$DATE))
tendance <- lm(trainData$HourlyDryBulbTemperature~1+t)
coeff <-coefficients(tendance)


plot(trainData$DATE,trainData$HourlyDryBulbTemperature, type='l', main = "Estimation de la tendance par régression linéaire", col='darkblue', size=0.01, xlab = 'Date', ylab = 'Température')
lines(trainData$DATE,tendance$fitted.values, col='red')
```

Le résultat est cohérent avec nos attentes. La valeur du coefficient associé à la pente est vraiment très faible (de l'ordre de $10^{-6}$) mais la variable **t** est significative dans le test de significtivité de Student. Le coefficient associé à l'intercept est $13,1$, ce qui est en accord avec la moyenne de la température que l'on a calculée précédemment ($13.009$).

Concernant la saisonnalité, on en remarque une annuelle avec un pic positif au milieu de l'année (l'été) et deux pics négatifs au début et à la fin de l'année (l'hiver). L'échelle des données étant grande, on ne distingue pas de possibles saisonnalités plus courtes. On représente donc la variable **HourlyDryBulbTemperature** sur le mois de juin 2014 :

```{r DONNEES_DESC_PLOT_MOIS, echo=FALSE, fig.height=3, fig.width=3, fig.align='center'}
data_w <- data[which(month(data$DATE)==6 & year(data$DATE)==2014),]

# Plot avec ggplot2
ggplot(data_w, aes(x=DATE, y=HourlyDryBulbTemperature)) +
  geom_line(color="darkblue", size=0.5) + scale_y_continuous(name="Température") + ggtitle("Température du mois de Juin 2014") +  theme(plot.title = element_text(hjust = 0.5))
```

On remarque ici une nouvelle saisonnalité : une saisonnalité journalière avec un pic positif à la moitié de la journée (le midi) et des pics négatifs au début et à la fin de la journée (le matin et le soir).

La variable **HourlyDryBulbTemperature** semble donc posséder 2 saisonnalités : une annuelle et une journalière. On peut de plus les interpréter par les saisons et le cycle jour/nuit. 

On veut analyser ces deux saisonnalités en faisant 2 croisements par facteur : le premier par mois pour la saisonnalité annuelle et le second par heure pour la saisonnalité journalière.


```{r DONNEES_DESC_BOXPLOT_MOIS, echo=FALSE, fig.height=4, fig.width=4, fig.align='center'}
mois <- as.factor(format(data$DATE,"%m"))
boxplot(data$HourlyDryBulbTemperature~mois,col="lightblue",pch=20, xlab = "Mois", ylab = "Température", main="Température journalière / boîtes à moustaches mensuelles")
```

On observe de nouveau la saisonnalité de la température selon les mois et les saisons de l'année. Ce que l'on peut noter de nouveau est que la plage des valeurs prises en hiver est bien plus étendue que celle des valeurs prises l'été. On observe également la présence de valeurs aberrantes que l'on peut aussi deviner sur le graphique de la température sur 10 ans.

Représentons cette fois-ci la température selon les heures :

```{r DONNEES_DESC_PLOT_HEURES, echo=FALSE, fig.height=4, fig.width=4, fig.align='center'}
heure <- as.factor(format(data$DATE,"%H"))
boxplot(data$HourlyDryBulbTemperature~heure,col="lightblue",pch=20, xlab="Heure", ylab="Température", main="Température journalière / boîtes à moustaches horaires")
```

On observe bien la saisonnalité journalière avec des valeurs hautes de la température l'après-midi, lorsque le Soleil est levé. Ce graphique ne nous donne pas beaucoup plus d'informations et on s'attendait à une plus grande variance de la température le long des journées. Cependant, la moyenne selon les heures étant calculée sur tous les mois, on mélange les hautes températures de l'été avec les basses températures de l'hiver, d'où la faible variance.

La dernière étape de notre analyse descriptive est l'étude de l'autocorrélogramme où l'on doit distinguer une auto-corrélation toutes les 24 valeurs pour la saisonnalité journalière et une auto-corrélation toutes les $24 \times 365.25 = 8766$ valeurs pour la saisonnalité annuelle. On représente aussi, à côté de chaque graphe d'autocorrélation, un graphe de l'autocorrélation partielle. Voici l'interprétation de cette quantité : on peut projeter une série chronologique sur ses valeurs passées selon la formule $P\left(Y_{t}\right)=\sum_{j=1}^{k} b_{k, j} Y_{t-j}$. L'autocorrélation partielle évaluée en $k$ correspond au coefficient $b_{k,k}$. Une autre interprétation de l'autocorrélation partielle en $k$ est que l'on analyse la corrélation entre $X_1$ et $X_k$ en retirant les interférences des termes intermédiaires $X_2, \dots, X_{k-1}$. C'est donc une espèce de "débruitage", et on voit bien que son graphe est moins chargé que le graphe $\texttt{acf}$.

Pour observer l'auto-corrélation journalière, on représente l'autocorrélogramme sur 96 valeurs (4 jours) :

```{r DONNEES_DESC_AUTOCORREL_PLOT_FUNCTION, message=FALSE, warning=FALSE, include=FALSE}
ggplot.corr <- function(data, lag.max = 24, ci = 0.95, large.sample.size = TRUE, horizontal = TRUE,...) {
  
  suppressMessages(require(ggplot2))
  suppressMessages(require(dplyr))
  suppressMessages(require(cowplot))
  
  if(horizontal == TRUE) {numofrow <- 1} else {numofrow <- 2}
  
  list.acf <- acf(data, lag.max = lag.max, type = "correlation", plot = FALSE)
  N <- as.numeric(list.acf$n.used)
  df1 <- data.frame(lag = list.acf$lag, acf = list.acf$acf)
  df1$lag.acf <- dplyr::lag(df1$acf, default = 0)
  df1$lag.acf[2] <- 0
  df1$lag.acf.cumsum <- cumsum((df1$lag.acf)^2)
  df1$acfstd <- sqrt(1/N * (1 + 2 * df1$lag.acf.cumsum))
  df1$acfstd[1] <- 0
  df1 <- select(df1, lag, acf, acfstd)
  
  list.pacf <- acf(data, lag.max = lag.max, type = "partial", plot = FALSE)
  df2 <- data.frame(lag = list.pacf$lag,pacf = list.pacf$acf)
  df2$pacfstd <- sqrt(1/N)
  
  if(large.sample.size == TRUE) {
    plot.acf <- ggplot(data = df1, aes( x = lag, y = acf)) +
    geom_area(aes(x = lag, y = qnorm((1+ci)/2)*acfstd), fill = "#B9CFE7") +
    geom_area(aes(x = lag, y = -qnorm((1+ci)/2)*acfstd), fill = "#B9CFE7") +
    geom_col(fill = "#4373B6", width = 0.7) +
    scale_x_continuous(breaks = seq(0,max(df1$lag),6)) +
    scale_y_continuous(name = element_blank(), 
                       limits = c(min(df1$acf,df2$pacf),1)) +
    ggtitle("ACF") +
    theme_bw()
    
    plot.pacf <- ggplot(data = df2, aes(x = lag, y = pacf)) +
    geom_area(aes(x = lag, y = qnorm((1+ci)/2)*pacfstd), fill = "#B9CFE7") +
    geom_area(aes(x = lag, y = -qnorm((1+ci)/2)*pacfstd), fill = "#B9CFE7") +
    geom_col(fill = "#4373B6", width = 0.7) +
    scale_x_continuous(breaks = seq(0,max(df2$lag, na.rm = TRUE),6)) +
    scale_y_continuous(name = element_blank(),
                       limits = c(min(df1$acf,df2$pacf),1)) +
    ggtitle("PACF") +
    theme_bw()
  }
  else {
    plot.acf <- ggplot(data = df1, aes( x = lag, y = acf)) +
    geom_col(fill = "#4373B6", width = 0.7) +
    geom_hline(yintercept = qnorm((1+ci)/2)/sqrt(N), 
               colour = "sandybrown",
               linetype = "dashed") + 
    geom_hline(yintercept = - qnorm((1+ci)/2)/sqrt(N), 
               colour = "sandybrown",
               linetype = "dashed") + 
    scale_x_continuous(breaks = seq(0,max(df1$lag),6)) +
    scale_y_continuous(name = element_blank(), 
                       limits = c(min(df1$acf,df2$pacf),1)) +
    ggtitle("ACF") +
    theme_bw()
    
    plot.pacf <- ggplot(data = df2, aes(x = lag, y = pacf)) +
    geom_col(fill = "#4373B6", width = 0.7) +
    geom_hline(yintercept = qnorm((1+ci)/2)/sqrt(N), 
               colour = "sandybrown",
               linetype = "dashed") + 
    geom_hline(yintercept = - qnorm((1+ci)/2)/sqrt(N), 
               colour = "sandybrown",
               linetype = "dashed") + 
    scale_x_continuous(breaks = seq(0,max(df2$lag, na.rm = TRUE),6)) +
    scale_y_continuous(name = element_blank(),
                       limits = c(min(df1$acf,df2$pacf),1)) +
    ggtitle("PACF") +
    theme_bw()
  }
  cowplot::plot_grid(plot.acf, plot.pacf, nrow = numofrow)
}
```

```{r DONNEES_DESC_AUTOCORREL_JOURNALIERE, echo=FALSE, warning = FALSE, fig.height=4}
data.xts <- xts(data$HourlyDryBulbTemperature,order.by = data$DATE)
#acf(data$HourlyDryBulbTemperature,na.action = na.pass,lag.max = 96)

ggplot.corr(data = data$HourlyDryBulbTemperature, lag.max = 96, ci= 0.95, large.sample.size = FALSE, horizontal = TRUE)
```

On observe une très forte auto-corrélation sur ces 4 jours avec des valeurs d'auto-corrélation proches de 1. On voit aussi la saisonnalité journalière comme prévu. Etant donné que cette saisonnalité est incluse dans la saisonnalité annuelle, l'auto-corrélation journalière suit une tendance, ici à la baisse.

Pour observer l'auto-corrélation annuelle, on représente l'autocorrélogramme sur $8766 \times 2 = 17532$ valeurs (2 ans) :

```{r DONNEES_DESC_AUTOCORREL_ANNUELLE, echo=FALSE, message=FALSE, warning=FALSE, fig.height=4}
#data.xts <- xts(data$HourlyDryBulbTemperature,order.by = data$DATE)

#acf(data$HourlyDryBulbTemperature,na.action = na.pass,lag.max = 17532, main="",)

ggplot.corr(data = data$HourlyDryBulbTemperature, lag.max = 15000, ci= 0.95, large.sample.size = TRUE, horizontal = TRUE)
```

On observe la saisonnalité annuelle comme prévu toutes les 8766 valeurs. Les valeurs des hivers sont auto-corrélées positivement et les valeurs des étés sont auto-corrélées négativement, ce qui correspond bien à l'allure de la saisonnalité annuelle.

Enfin, concernant la stationnarité de la température, les 2 saisonnalités impliquent que l'espérance de la température dépend du temps et donc la température n'est pas stationnaire. On peut de plus l'observer sur les 2 autocorrélogrammes où l'auto-corrélation est très forte avec des maximums globaux pour les lags multiples de $365.25 \times 24$ (saisonnalité annuelle) et des maximums locaux pour les lags multiples de $24$ (saisonnalité journalière).

# Modèles MSTS

La première approche est d'utiliser la classe $\texttt{msts}$ du package $\texttt{forecast}$ pour le logiciel R. C'est une classe développée en 2011 pour traiter les séries chronologiques ayant des saisonnalités multiples. On va donc utiliser ce modèle "tout prêt" pour le comparer à un modèle GAM.

```{r MSTS_MODELE}
trainDataMSTS <- msts(trainData$HourlyDryBulbTemperature, seasonal.periods = c(24, 24*365))
```

Voici une décomposition des données faite par la fonction $\texttt{mstl}$.

```{r MSTS_DECOMPOSITION, echo=FALSE, fig.height=4}
# Décomposition
modeleMSTS <- mstl(trainDataMSTS)
autoplot(modeleMSTS, main="                            Décomposition par la fonction mstl")
```

On voit que les saisonnalités journalières et annuelles sont bien capturées, et que les résidus sont centrés et à peu près de variance constante, ce qui est une bonne indication visuelle de stationnarité. 

```{r MSTS_PREVISION, include = FALSE}
# Enregistrement du temps initial
temps_initial_train_msts <- Sys.time()

# Prédiction pour un an
predMSTS <- stlf(trainDataMSTS, h = (24*365))

# Enregistrement du temps final et temps total
temps_final_train_msts <- Sys.time()
temps_modele_msts <- temps_final_train_msts - temps_initial_train_msts
temps_modele_msts #  secs Mac 2015
```

On réalise ensuite une prévision en utilisant ce modèle. Observons les graphes de la prédiction en comparaison aux données d'entraînement et le graphe de la partie prédie. On voit que les 2 saisonnalités sont présentes dans la prédiction.

```{r MSTS_GRAPHES_1, echo=FALSE, fig.height=3, fig.width=3}
# Graphe de la prédiction totale
autoplot(predMSTS, main="", ylab="Température", xlab="Temps")
```
```{r MSTS_GRAPHES_2, echo=FALSE, fig.height=3, fig.width=3}
# Graphe seulement de la partie prévue
#plot(as.numeric(predMSTS$mean), type = 'l')
df_predMSTS <- data.frame(as.numeric(predMSTS$mean))
names(df_predMSTS) <- 'predMSTS'
df_predMSTS$Indice <- index(df_predMSTS)
ggplot(df_predMSTS, aes(x=Indice, y=predMSTS)) +
  geom_line(color="darkred", size=0.2) + scale_y_continuous(name="Température")
```


On peut calculer l'erreur RMSE entre la prédiction et les données de test. Le résultat est $\texttt{RMSE = 5.379212}$. On comparera ce résultat avec celui du modèle GAM que l'on construit dès maintenant. 

```{r MSTS_RMSE, include=FALSE}
# On retire la dernière donnée pour avoir la bonne taille
testData2 <- head(testData$HourlyDryBulbTemperature, -1)

# RMSE pour le modèle MSTS.
rmse(as.numeric(predMSTS$mean), testData2)
```

# Modèle GAM

Les modèles additifs généralisés (GAM) ont été introduits dans [@hastie1990generalized] et son but est d'ajouter à une régression linéaire des termes non-linéaires. L'objectif est donc de modéliser des relations non-linéaires.

## La théorie

Mathématiquement on écrit un GAM comme

$$
y_{i}=\beta_0 + X_{i} \beta+f_{1}\left(x_{1, i}\right)+f_{2}\left(x_{2, i}\right)+f_{3}\left(x_{3, i}, x_{4, i}\right)+\ldots+\varepsilon_{i}
$$

On voit bien que la partie linéaire est toujours présente avec le terme $X_i \beta$ où $X_i$ est le plan formé des variables $(x_{k,i})_k$. Les fonctions $f_j$ sont supposées lisses, dépendantes d'au plus 2 variables et elles sont estimées selon un choix de base. Les résidus $\varepsilon_i$ doivent être i.i.d., centrés, et de variance constante (mais pas nécessairement gaussiens).

On garde beaucoup de similarités avec l'approche de la régression linéaire : on va estimer les bons coefficients $\beta$ et les fonctions $f_j$ en minimisant un problème de moindres-carrés. On pourrait proposer

$$
\min _{\beta, f_{j}}\left\|y-\beta_0 - X \beta-f_{1}\left(x_{1}\right)-f_{2}\left(x_{2}\right)+\ldots\right\|^{2}
$$

Cependant, comme dans le cas linéaire, il convient de "régulariser" ce problème. On veut éviter la surapprentissage et avoir des fonctions qui n'oscillent pas trop fortement, i.e., limiter le niveau de non-linéarité de notre modèle. Cette seconde considération nous suggère de faire une régularisation de type Ridge sur les dérivées secondes des fonctions $f_j$ :

$$
\min _{\beta, f_{j}}\left\|y-\beta_0 - X \beta-f_{1}\left(x_{1}\right)-f_{2}\left(x_{2}\right)+\ldots\right\|^{2}+\lambda_{1} \int f_{1}^{\prime \prime}(x)^{2} d x+\lambda_{2} \int f_{2}^{\prime \prime}(x)^{2} d x+\ldots
$$

On va expliquer plus tard comment choisir les paramètres $\lambda_i$ de régularisation.

On observe déjà que les fonctions $f_j$ seront estimées selon un choix de base de fonctions non-linéaires. Il y a plusieurs choix possibles et cela change en fonction des données. Notamment, on utilisera des splines cubiques de manière générale, et des splines cycliques si nécessaire pour modéliser des parties saisonnales. Quand on choisit des splines, c'est nécessaire aussi de spécifier le nombre de nœuds à utiliser.

Finalement, voici une liste des inconnues du problème : on doit choisir la base de fonctions non-linéaires, le choix du nombre $k$ de nœuds, on doit estimer les coefficients des $f_j$ dans cette base, les coefficients $\beta$ de la partie linéaire du modèle, et finalement les paramètres de régularisation $\lambda_i$. 

### Validation croisée

On décrit maintenant la procédure de validation croisée ("cross-validation" en anglais). Cette procédure est très utile pour l'estimation des paramètres du modèle, comme les paramètres de pénalisation $\lambda_i$, et le nombre de noeuds $k$ dans la base de splines. Il y a plein d'autres applications, comme la sélection de variables, la prévision du score dans une compétition comme Kaggle et le choix de modèles.

#### Validation croisée ordinaire

Elle consiste à partitionner le jeu de données d'entraînement en $k$ parties, puis entraîner un modèle sur $k - 1$ des parties et faire une prédiction dans la partie restante. Cela estime l'erreur de prédiction du modèle. Cependant on observe que il y a une combinatoire non-triviale dans cette procédure, et donc cette approche est en générale lente. 

#### Validation croisée géneralisée

On décrit maintenant une idée originalement introduite dans [@golub]. Dans cet article, ils déduisent un estimateur du paramètre de régularisation $\lambda$ (dans le cas d'une régularisation Ridge spécifiquement).

Cette quantité peut être aussi vue comme un estimateur du score de la validation croisée ordinaire. Ainsi, on s'approche d'un tel score sans avoir directement analysé chaque sous-modèle : on minimise numériquement une fonction, ce qui est beaucoup moins cher numériquement.

L'estimateur qu'ils trouvent est

$$
V_{g}(\lambda)=n \| y-X \widehat{\beta}_{\lambda} \|^{2} /\left(n-\operatorname{tr}\left(F_{\lambda}\right)\right)^{2}
$$

où $\widehat{\beta}_{\lambda}=F_{\lambda} \widehat{\beta}_{0}$, avec

$$
\widehat{\beta}_{0}=\left(X^{T} X\right)^{-1} X^{T} y \quad \text{et} \quad F_{\lambda}=\left(X^{T} X+\sum \lambda_{j} S_{j}\right)^{-1} X^{T} X
$$

On remarque que $\widehat{\beta}_0$ est l'estimation de $\beta$ dans le cas non-régularisé.

## Implémentation

### Approche naïve

On pourrait écrire un modèle GAM en ajoutant comme variables l'heure de la journée **Heure**, le numéro de la semaine dans l'année **NumSem** et le numéro du jour dans l'année **NumJour**. Les relations entre chacune de ces variables et la température étant non-linéaires, on utilise des fonctions *smooth s()*. Les splines choisis sont des splines cubiques cycliques. On les choisit cycliques car cela entraîne la continuité entre le début et la fin du *fitting*, ce qui est primordial lorsqu'on étudie des phénomènes cycliques comme la température. 

```{r GAM_NAIVE, eval=FALSE}
# Modèle avec toutes les variables
modelGAM <- gam(HourlyDryBulbTemperature ~ 
                       s(Heure, bs = 'cc', k = 24)  +
                       s(NumSem, bs = 'cc', k = 52) +
                       s(NumJour, bs = 'cc', k =365),
                       data = as.data.frame(trainData))
```

On voit que si l'on essaye d'utiliser la variable $\texttt{NumJour}$, qui indique à quel jour de l'année on est, on a des problèmes dans le choix du nombre de noeuds $k$. Soit on prend $k$ petit, mais ainsi on perd de l'information sur la modélisation et la prédiction, soit on prend $k$ grand (idéalement $k_{\text{max}} = 365$) et le temps d'exécution du code est très long. On aimerait alors utiliser une autre variable en limitant les pertes sur les performances du modèle.

### Sélection de variables

Une idée est d'observer que dans une semaine donnée, l'évolution de la température sur une journée ne diffère pas des autres journées de la semaine. C'est-à-dire que dans une semaine fixée, la saisonnalité journalière possède une tendance constante égale à la moyenne de la semaine en question. Cela indique que les jours de cette semaine sont équivalents, dans le sens que pour estimer la température à 15h, peu importe si c'est lundi, jeudi ou dimanche : si on connaît la moyenne de la semaine, il faut juste connaître la moyenne de température à 15h. On assume donc le choix de remplacer le numéro du jour dans l'année par le numéro de la semaine dans l'année. On vient de donner une explication visuelle et intuitive, et on donnera une justification basée sur les performanes dans la suite.  

Ceci dit, on a $\approx 52$ semaines dans une année, et $24$ heures par jour. Ainsi, le nombre total de noeuds que l'on aura besoin si l'on utilise que ces deux variables est la somme $52 + 24 = 76$, beaucoup moins que les $365$ précédents (rien que pour le numéro du jour), et associés à deux variables différentes. On crée donc notre modèle GAM que l'on appelle **modelGAM** et on étudie son résumé :

```{r GAM_MODELE, include=FALSE}
# Enregistrement du temps initial
temps_initial_train_gam <- Sys.time()

# Création du modèle
modelGAM <- gam(HourlyDryBulbTemperature ~ 
                       s(Heure, bs = 'cc', k = 24) +
                       s(NumSem, bs = 'cc', k = 52),
                       data = as.data.frame(trainData))

# Enregistrement du temps final et calcul du temps total
temps_final_train_gam <- Sys.time()
temps_modele_gam <- temps_final_train_gam - temps_initial_train_gam
temps_modele_gam # 6.253649 secs Mac 2015

# Sommaire du modèle
summary(modelGAM)
```

```{r, echo = FALSE}
summary(modelGAM)
```

Soulignons quelques statistiques clés : on a $R_{\text{ajusté}} = 0.83$, et le score de validation croisée généralisée (qui estime la performance de prévision) est $\text{GCV} = 15.678$. On note que cette valeur est essentiellement la même que celle obtenue dans le modèle GAM avec plus de variables (et qui prend beaucoup plus de temps pour s'exécuter). Les tests de significativé de Student sont tous très significatifs, ce qui est un bon point pour notre modèle. On trace ensuite les fonctions *smooth* de notre base afin de les étudier :

```{r GAM_PLOTS, echo=FALSE, fig.height=3.5}
# Plot du modèle ajusté
layout(matrix(1:2, ncol = 2))
plot(modelGAM, select = 1, main = "Terme lisse s(Heure)", ylab = "Terme lisse ajusté", col="darkred")
plot(modelGAM, select = 2, main = "Terme lisse s(NumSem)", ylab = "Terme lisse ajusté", col="darkblue")
layout(1)
```

Ces graphes représentent les fonctions lisses ajustées $f(Heure)$ et $f(NumSem)$ selon la base de spline cycliques choisie dans le modèle GAM. Le premier graphe nous montre que la température semble se concentrer à la fin du matin chaque jour, et que la température est plus haute à la moitié de l'année (ce qui correspond à l'été). On regarde bien le caractère cyclique par le fait que dans les deux graphes la température à la fin est la même que la température au début. Finalement, on voit aussi que les intervalles de confiance sont très ajustés aux courbes, ce qui signifie que ce résultat est précis.

On crée des variables auxiliaires **Temps** pour la prédiction, qui sont juste une numérotation des observations des données d'entraînement **trainData** et des données de test **testData**. C'est une manière pratique de manipuler le temps sans utiliser les variables du type $\texttt{POSIXt}$. Après avoir ajusté le modèle, on fait la prédiction et on trace les données d'entraînement suivies de la prédiction.

```{r GAM_AUXILIAIRES, include=FALSE}
# Définition d'une variable temporelle indices au lieu de dates
temps = c(1:(nrow(trainData) + nrow(testData)))  # Variable temporelle incluant le futur
trainData$Temps <- temps[1:nrow(trainData)]      # Création d'une variable explicative de temps
testData$Temps <- tail(temps, nrow(testData))    # tail prend les dernières nrow(testData) composantes de temps (prédiction)
```


```{r GAM_PREVISION, include=FALSE}
# Enregistrement du temps initial
temps_initial_predict_gam <- Sys.time()

# Prédiction
predGAM <- predict(modelGAM, newdata = testData)

# Enregistrement du temps final
temps_final_predict_gam <- Sys.time()
temps_predict_gam <- temps_final_predict_gam - temps_initial_predict_gam
temps_predict_gam # 0.4337702 secs Mac 2015

# Sauvegarde dans un csv si nécessaire
#write.csv(predGAM, 'predictionGAM.csv')
```


```{r GAM_GRAPHES, echo=FALSE, fig.height=4}
# Plot de la prévision en comparaison avec les donnes d'entraînement
plot(temps, c(trainData$HourlyDryBulbTemperature, predGAM), type='l', ylab = "Température", xlab = "Temps (en indices)", main="Prédiction d'un an avec le modèle GAM")
abline(v = tail(trainData$Temps, n = 1), col='red', lty = 2, lwd = 2)

#df_GAM_prevision <- data.frame(c(trainData$HourlyDryBulbTemperature, predGAM))
#df_GAM_prevision$Temps <- index(df_GAM_prevision)
#df_GAM_prevision$Group <- as.character(1)

#replacement_values <- rep(as.character(2), length(testData$indices))
#replacement_indices <- tail(df_GAM_prevision$Temps, length(testData$indices))

#replace(df_GAM_prevision$Group, replacement_indices, replacement_values)

#names(df_GAM_prevision) <- c('Température', 'Temps', 'Group')

#ggplot(df_GAM_prevision, aes(x = Temps, y = Température)) +
#  geom_line(aes(color = Group)) +
#  scale_color_manual(values = c("darkred", "darkblue")) +
#  theme_classic()
```

Faisons un graphe avec une échelle plus petite pour confirmer l'existence de la saisonnalité journalière dans ce modèle.

```{r GAM_GRAPHE_ZOOM, echo=FALSE, fig.height=3.5}
layout(matrix(1:2, ncol = 2))

# Une semaine. On saute les premiers cinq jours car la prédiction ne commence pas exactement dans une semaine
plot(predGAM[(24 * 5):(24 * (5 + 7))], type = 'l', ylab = 'Prédiction GAM', xlab = 'Temps (en indices)', main = "Prédiction d'une semaine")

# Un mois
plot(predGAM[(24 * 5):(24 * (31))], type = 'l', ylab = 'Prédiction GAM', xlab = 'Temps (en indices)', main="Prédiction d'un mois")

layout(1)
```

Le plot d'une semaine révèle bien que l'on a une saisonnalité journalière. Le plot d'un mois montre bien que, à chaque semaine, on ne différencie pas les jours les uns des autres, mais d'une semaine à l'autre on change la température moyenne. La structure hebdomadaire de la modélisation où la température moyenne ne change pas n'a aucun sens concret de manière locale mais elle est significative de manière globale. Cela est dû à l'utilisation de la variable **NumSem** au lieu de la variable **NumJour**.

```{r GAM_RMSE, include=FALSE}
rmse(testData$HourlyDryBulbTemperature, predGAM)
```

### Comparaison avec msts

On calcule le score RMSE par rapport aux données de test et on obtient $3.80328$. Or, on voit en comparant le RMSE des modèles GAM et MSTS que le modèle GAM performe considérablement mieux : $3.80328$ (GAM) contre $5.37921$ (MSTS). Sur le temps d'exécution, on a $7.21889s$ (GAM) et $4.27370s$ (MSTS). Par rapport au nombre des données considérées (presque $100.000$ observations) on considère que même si le modèle GAM prend quelques secondes de plus, étant donné sa performance, il est compétitif avec le modèle MSTS.

## Amélioration du modèle : intéraction entre variables ?

L'une des manières de compléter un modèle **GAM** est l'ajout de fonctions représentant les interactions entre les variables. Plus précisément, on cherche à savoir s'il existe des interactions non-linéaires entre les variables sur l'estimateur du modèle **GAM**. Si c'est le cas, on peut ajouter dans le modèle une fonction *smooth* $s(x_1,x_2)$. On obtient alors l'équation suivante dans un GAM à 2 variables :

$$
y = \beta_1 + \beta_2 x_1 + \beta_3 x_2 + \beta_4 f_1 (x_1) + \beta_5 f_2 (x_2) + \beta_6 f_3 (x_1,x_2)
$$
On peut d'ailleurs utiliser un produit tensoriel pour représenter les interactions se produisant à différentes échelles. On aura alors $f_3(x_1,x_2)=f_{3,1}(x_1)f_{3,2}(x_2)$. 

Un point important à noter dans l'ajout de fonctions représentant l'interaction entre variables est le caractère linéaire de l'interaction. Si l'interaction est linéaire, alors on obtient $f_3(x_1,x_2)=f_{3,1}(x_1) + f_{3,2}(x_2)$ et alors l'intérêt de la fonction bivariée en $(x_1,x_2)$ disparaît. En effet, on pourra alors réécrire le modèle **GAM** comme 

$$
y = \beta_1 + \beta_2 x_1 + \beta_3 x_2 + \beta_4 \underbrace{\left( f_1 (x_1) + f_{3,1}(x_1) \right)}_{= g_1(x_1)} + \beta_5 \underbrace{\left( f_2 (x_2) + f_{3,2}(x_2) \right)}_{=g_2(x_2)}
$$

Revenons à notre étude. Notre modèle GAM possède pour l'instant un intercept et une fonction *smooth* pour chaque variable. On cherche maintenant à étudier s'il existe une interaction non-linéaire entre les variables **Heure** et **NumSem** sur la température. Intuitivement, on se doute qu'il existe une interaction entre ces deux variables sur la température. En effet, la température sur une journée peut varier différemment selon la saison. Si c'est le cas, il faut que cette différence soit assez importante pour que l'ajout d'un terme d'interaction dans le GAM soit significatif en terme d'amélioration des performances. Par exemple, on peut se demander si la température évolue de la même manière sur une journée en hiver et en été. Pour étudier cette interaction, on va procéder en 2 étapes : 

* une étude graphique grâce à la fonction *vis.gam*
* une étude des performances des modèles GAMs avec ou sans terme d'interaction

### Etude graphique :

```{r INTERACTION_ETUDE_1, echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, fig.height=4}
vis.gam(modelGAM, view = c("Heure", "NumSem"), plot.type = "persp", theta = 220, main="Interaction entre les variables sur l'estimateur")
```

On remarque qu'il existe bien une interaction des variables **Heure** et **NumSem** sur l'estimateur du modèle. On observe un pic positif et une symétrie par rapport au centre des valeurs de **NumSem** qui correspond à l'été. De même, on observe un pic un peu avant le centre des valeurs de **Heure**, ce qui correspond au lever et au coucher du Soleil. On dessine le même graphique selon deux angles différents afin d'avoir un aperçu global :

```{r INTERACTION_ETUDE_2, echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, fig.height=4}
layout(matrix(1:2, ncol = 2))

vis.gam(modelGAM, view = c("Heure", "NumSem"), plot.type = "persp", phi = 35)
vis.gam(modelGAM, view = c("Heure", "NumSem"), plot.type = "persp", phi = 35,theta=180)

layout(1)
```

Comme dit précédemment, on voit bien qu'il y a une interaction dans notre modèle. Il reste maintenant à voir si cette interaction est linéaire dans le sens où on peut la décomposer comme une fonction de **Heure** sommée à une fonction de **NumSem**. On voit sur les 2 graphiques ci-dessus que pour une valeur de **NumSem** fixée et selon les valeurs de **Heure**, les valeurs de l'estimateur semblent évoluées de la même manière. On peut aussi l'observer lorsque l'on trace les lignes de niveaux de l'estimateur :

```{r INTERACTION_ETUDE_3, echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, fig.height=4}
vis.gam(modelGAM, view = c("Heure", "NumSem"), plot.type = "contour", nlevels = 10, main="Lignes de niveau de l'estimateur selon les variables")
```

On voit que la saisonnalité journalière est presque indépendante du numéro de la semaine. On aurait d'ailleurs le même résultat en remplaçant les numéros de la semaine par le numéro des jours. Visuellement, l'interaction de **Heure** et **NumSem** sur l'estimateur semble donc linéaire. Poursuivons notre étude par la comparaison des performances des modèles.

### Etude des performances :

```{r TABLEAU, echo=FALSE, message=FALSE, warning=FALSE}
#install.packages("kableExtra")
library(kableExtra)
Performances <- c("Modèle","Temps de création du GAM (en s)","R-ajusté","Score GCV","Score RMSE")
Performances <- cbind(Performances,c("s(H)+s(NS)","2.551","0.830","15.673","3.790"))
Performances <- cbind(Performances,c("s(H)+s(NS)+s(H,NS)","6.096","0.832","15.487","3.780"))
Performances <- cbind(Performances,c("s(H)+s(NS)+ti(H,NS)","8.333","0.832","15.502","3.785"))
```


Nous avons présenté ici un raisonnement descriptif sur des graphiques mais on peut aussi utiliser un argument basé sur des performances du modèle : le temps de création du GAM (en secondes et arrondi au millième), le R-ajusté et le GCV du GAM, et le RMSE de la prédiction test. On note **Heure** par **H** et **NumSem** par **NS**. Voici les résultats :

<!---<p align="center">
  <img src="Capture.PNG">
</p>
<p align="center">
</p>--->

![](./Capture.PNG){width=60%}

On voit tout d'abord que le temps de création du modèle GAM est doublé voire triplé lorsqu'on ajoute un terme d'interaction. Les modèles avec interaction sont donc plus coûteux à construire et c'est normal car on ajoute une fonction à notre base. Le gain sur le R-ajusté est très faible : 2 millièmes. De même, le gain sur le GCV est de l'ordre du dizième et le gain sur le RMSE est de l'ordre du centième. L'apport d'un terme d'interaction est très peu significatif alors que le temps de calcul est bien plus important. Cela confirme notre étude descriptive sur l'interaction entre les variables que l'on peut considérer comme linéaire. Notre modèle choisi est donc celui sans terme d'interaction.

*Remarque :* Si dans notre jeu de données on n'observe pas d'interaction non-linéaire, cela ne veut pas dire qu'il n'existe pas de telle interaction dans un autre jeu de données où on mesure la température dans un autre endroit. On ne pourra donc pas admettre ce résultat pour n'importe quel jeu de données de température. On s'attendait d'ailleurs à observer une interaction non-linéaire dans ce jeu de données car on pensait que la température journalière variait différemment selon la saison et cela de manière assez importante pour avoir une meilleure modélisation. Il serait intéressant d'étudier cela en prenant des données de température dans d'autres endroits. 

## Vérification du modèle et étude des résidus

Maintenant que nous avons défini notre modèle, on peut étudier les résidus du modèle pour déterminer sa qualité. La fonction *gam.check* nous fournit un test sur la dimension des splines et des graphiques intéressants sur les résidus :

```{r ETUDE DES RESIDUS, echo=FALSE, message=FALSE, warning=FALSE, results='hide', fig.keep='all'}
gam.check(modelGAM)
```

Le test sur les valeurs des paramètres **k** nous indique que ceux que l'on a renseigné dans les splines de notre modèle ne sont pas trop petits.

L'allure de l'histogramme est très satisfaisante car il semble représenter que les résidus suivent une loi normale centrée. Le QQ-plot renforce cette intuition mais les queues sont un peu trop épaisses de part et d'autre. C'est un phénomène de *Kurtosis*. Il y a donc une trop grande variance des deux côtés de la loi normale.

Le graphique "Resids vs. linear pred." montre que l'homoscédasticité des résidus n'est pas parfaitemant respectée avec une plus grande variance pour le premier quart des valeurs de *linear predictor*. L'allure générale est cependant satisfaisante pour le reste des valeurs *linear predictor*. De plus, la variance est centrée sur l'ensemble des valeurs. 

On peut faire la même analyse du graphique "Response vs. Fitted Values". En effet, la relation entre les deux grandeurs est clairement linéaire et la pente est proche de 1. Cependant, la pente n'est pas exactement 1 et on observe ici aussi une plus grande variance pour le premier quart des valeurs de *Fitted Values*. 

On conclut l'étude des résidus par l'observation de son caractère stationnaire. Lors de l'étude de la stationnarité de la température, on avait remarqué que les 2 saisonnalités étaient bien présentes sur les autocorrélogrammes. On représente donc 2 autocorrélogrammes avec une échelle journalière (4 jours) puis annuelle (2 ans) pour voir si les 2 saisonnalités sont toujours présentes dans les résidus :

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.height=3.5}
layout(matrix(1:2, ncol = 2))

#main="ACF (lag = 2 ans)",
#main="ACF (lag = 4 jours)"

acf(modelGAM$residuals,lag.max = 24*365*2, main="")
acf(modelGAM$residuals,lag.max = 24*4, main="")

layout(1)
```

Sur le premier graphique, on ne distingue plus la forte autocorrélation annuelle. Cela veut dire que notre modèle modélise correctement la saisonnalité annuelle et on pouvait s'y attendre car cette saisonnalité est très régulière dans le temps et sa fréquence est faible sur le jeu de données.

Sur le second graphique, on distingue la saisonnalité journalière des résidus, ce qui est problématique. Cela veut dire que notre modèle ne parvient pas à modéliser correctement cette saisonnalité. Ce phénomène est peut-être dû à l'irrégularité de la saisonnalité journalière et sa forte fréquence, ou bien à un manque d'informations dans notre modèle. 

De manière générale, ces deux autocorrélogrammes montrent que les résidus ne sont pas stationnaires. On observe que l'autocorrélation diminue fortement à l'échelle annuel mais elle reste trop haute et n'appartient pas à l'intervalle de confiance. La raison de ce mauvais comportement semble être la mauvaise modélisation de la saisonnalité journalière. Pour déterminer cette intuition, on représente l'autocorrélogramme des résidus où on applique la fonction *diff()* avec le paramètre *differences = 24* pour retirer la saisonnalité journalière. 

```{r echo=FALSE, fig.height=4, message=FALSE, warning=FALSE, fig.align='center'}
# main="ACF (lag = 4 jours, différence = 24)"
acf(diff(modelGAM$residuals,differences = 24),lag.max = 24*4, main="")
```

Ces 2 graphiques confirment notre intuition. L'autocorrélation diminue de manière exponentielle et devient très faible. Les valeurs des ACF sont proches de l'intervalle de confiance. Lorsqu'elles sont incluses dans l'intervalle de confiance, on peut les considérer comme nulle et donc affirmer la stationnarité. Cependant, on distingue encore des valeurs de l'ACF en dehors de l'intervalle de confiance lorsque les valeurs de Lag approchent les multiples de 24. La saisonnalité journalière est donc encore présente dans les résidus mais de manière très faible et les valeurs de l'ACF sont beaucoup plus faibles que précédemment. On peut presque conclure la stationnarité des résidus après application de la fonction *diff()*.

On conclut notre étude du caractère stationnaire des résidus par la non stationnarité à cause de la mauvaise modélisation de la saisonnalité journalière. Cependant, nos résidus restent satisfaisant car la correction de ce problème pourrait conclure la stationnarité des résidus. Nous avons tenté de résoudre ce problème en ajoutant des variables, en modifiant les splines du GAM et même en ajoutant des termes d'interaction entre les variables. En effet, ce dernier pourrait régler le problème car si la variable **Heure** intéragie avec la variable **NumSem**, alors notre modèle ne prend pas en compte cette information et cela pourrait expliquer le mauvais comportement journalier. Cependant, l'ajout des termes d'interaction n'a pas amélioré la stationnarité des résidus (ni les observations précédentes sur leur répartition gaussienne).

Finalement, on construit un nouveau modèle **resModelGam** sur les résidus pour voir s'il peut modéliser la saisonnalité journalière restante. On l'étudie en utilisant son résumé et son autocorrélogramme.

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.height=4, fig.align='center'}
resModelGAM <- gam(modelGAM$residuals~s(trainData$Heure,bs='cc',k=24))
#summary(resModelGAM)
acf(resModelGAM$residuals, main="")
```

L'intercept et la fonction smooth *s(Heure,bs='cc',k=24)* ne sont pas significatifs dans les tests de significativités de Student. Le R-ajusté et le score GCV sont très mauvais et l'autocorrélogramme montre que le modèle **resModelGAM** ne parvient pas à modéliser la saisonnalité journalière. De plus, comme précédemment, en utilisant la fonction *diff()* avec le paramètre *differences = 24*, on obtient la stationnarité. On conclut que le problème ne vient pas directement de notre modèle **modelGAM** mais peut-être de la trop haute fréquence de la saisonnalité journalière ou bien d'un manque d'information dans notre modèle.

# Conclusion

Dans ce projet nous avons étudié des données avec saisonnalités complexes. Cela se caractérise par l'existence de deux saisonnalités en deux échelles très différentes (une étant journalière, l'autre annuelle).

Notre première approche est l'utilisation de la classe *MSTS* du package *forecast* dans R. Nous avons ainsi obtenu des résultats qui modélisent bien les deux saisonnalités, et ce modèle a été capable de faire une prévision d'un an avec les variations journalières présentes. Ensuite nous avons crée un modèle additif généralisé (GAM) avec 2 variables, chacune pour modéliser une saisonnalité. Après un choix de variables pertinent, nous avons réussi à faire une modélisation qui modélise les deux saisonnalités ainsi que faire une prévision avec un score RMSE meilleur que le modèle MSTS.

Lors de la création de notre modèle GAM, nous avons présenté une réflexion et une justification de chacun de nos choix : choix des variables, choix des splines, de leur paramètres et aussi l'étude de l'interaction de nos 2 variables sur le modèle. Nous avons vu que l'interaction est trop linéaire pour qu'elle ait un impact significatif sur les performances du modèles. Enfin, nous avons étudié les résidus afin d'évaluer l'efficacité du modèle. Le comportement des résidus est satisfaisant avec une répartition presque gaussienne et on peut presque les considérer comme un bruit blanc. Cependant, les résidus ne sont pas parfaits et nous avons vu que c'est surtout la saisonnalité journalière qui n'est pas parfaitement modélisée par le modèle qui provoque le comportement moyen des résidus. Une piste de résolution de ce problème est l'utilisation d'autres modèles et d'autres outils afin de modéliser d'une meilleure manière nos données.

# Références
